# LLM对话框项目

muggle-chat  -  AI流式对话平台

项目介绍：基于Vue3的轻量级AI对话平台，集成OpenAI API服务、支持多轮会话管理、实时流式响应、状态持久化与markdown渲染支持。

技术栈：Vue3 + Vue-Router + Pinia + TypeScript + Antdv + Axios +Vite

项目工作：

* 完成对平台功能的基本建设，侧边栏实现会话的增删改查，内容区实现消息列表展示与自动滚动到底部
* 封装axios拦截器，统一处理get/post请求与错误响应，实现完整的OpenAI API调用流程 
* 采用SSE流式传输通信，解析流式数据并同步更新UI，实现打字机效果
* 采用Vue3 Composition API + Pinia的响应式架构，实现消息管理和会话管理，解决不同组件状态同步问题 ，并使用localStorage持久化存储api key 和会话状态
* 使用插件完成markdown格式字符串转化和代码块高亮，并对文本块和代码块添加复制按钮
* 前端项目工程化，配置Eslint和husky规范代码，自动化部署Vercel

# 项目问答

## 简单介绍一下这个项目

```
这是参加字节前端青训营做的一个项目，一个基于Vue3的轻量级AI对话平台，集成OpenAI API服务，可以进行简单对话交流。支持多轮会话管理，实时流式响应，实现打字机的效果。响应消息以markdown格式渲染，并支持复制功能。我是从0到1把这个项目搭建起来的，主要的核心工作有：
1. 前端工程化的一些配置：比如配置ESlint和husky规范代码，把代码库提交到github，并配置vercel自动化部署
2. 基本布局的搭建：采用了两栏布局，左边侧边栏完成会话的增删改查，主体内容区完成消息的发送和展示，使用vue-router实现单页面应用。
3. 完成基本的状态管理：像API KEY和会话列表这些，各个页面和组件都是要用到并且需要持久化存储的，所以使用pinia全局管理这些状态，并且使用localStorage解决持久化问题
4. 完成OpenAI的API服务层：查看OpenAI的API文档，看需要携带哪些数据，统一封装请求，并且设请求拦截器给每一个请求头携带上API KEY，也是就token，设响应拦截器统一处理错误响应。同时请求头还要指定一下接收SSE流式数据的格式，并且通过下载进度回调函数来同步处理数据和渲染UI
5. 到这里就基本完成了，再处理一下一些交互的逻辑，这个项目就基本搭建完成了。
```

## 基础布局介绍，采用了什么布局

```
采用了两栏布局，分为侧边栏和主体内容区。使用flex布局实现的，将父容器的display属性设为flex，侧边栏固定宽度，主体内容区设flex属性为1，自动放大。侧边栏完成会话历史的展示以及增删改查，主体内容区分为三部分，头部放设置按钮，点击弹出API配置面板，中间完成消息列表展示，底部搜索框。
```

## 详细说一下项目的状态管理

```
主要分为两大模块，分别是会话管理和消息管理，会话和消息都是多个组件需要用到的并且需要持久化存储的，所以我采用pinia来进行全局管理，并且使用localStorage来存储。这里只需存储会话列表，消息列表存储在会话列表的每一条会话对象当中，只需要通过计算属性获取，也就是store的getters。触发会话列表状态变更的事件，有会话的增删改、消息的发送和响应这四个事件，所以这四个事件也要在store中定义，也就是store中的actions。最后将所有的states getters actions return出去，就可以在任意组件中使用。
```

## 详细说一下API服务层

```
API服务层主要是封装Axios实例对象，封装请求拦截器和响应拦截器，统一处理get/post请求和响应错误，解析流式响应数据和同步渲染UI。
1. 首先查看OpenAI的API文档，封装一下请求配置，确定需要携带的请求数据，主要是请求地址、模型、温度参数、流式响应这四个，温度参数是设置模型的随机性的，还有请求头需要设置一下接收的数据格式为流式数据，即'Accept'字段设为text/even-stream。
2. 设请求拦截器给每一条请求携带上API KEY，也就是token（这里使用的是JWT认证），设响应拦截器统一处理不同状态码的错误。
3. 在请求配置中的onDownloadProgress这个字段设进度回调函数，因为在这个字段我们可以实时获取到每一块流式响应数据，这个进度回调函数中处理流式响应数据，并返回处理后的数据
4. 将发送消息请求封装为一个函数，返回真正所需要的文本消息对象，供其他组件调用，并封装密钥管理函数，也一并统一export出去。
```

## 详细说一下流式数据处理

```
主要是API服务层的处理，以及UI的实时渲染
1. 首先根据OPenAI API文档规定，请求携带数据的stream字段设为true，并设请求头的accept字段为text/event-stream,,确保响应数据为流式数据。
2. 在请求配置的onDownloadProgress字段设进度回调函数，每当有新数据发送过来时，都会触发一次进度回调函数，所以再在这个函数中我们可以实时获取到流式数据块，对其进行处理并实时更新UI。
3. API返回的流式数据格式为data:{id: choices:[{'delta':{content:''}}]}，是一个字符串，里面的content就是所需要的消息，我们需要提取出来。首先使用字符串的replace方法，把data:替换成空字符移除掉，此时剩下对象字符串，再使用JSON.Parse将对象转化为JSON格式的字符串，我们就可以提取出content消息字段。
3. 然后将最新响应消息传给store中更新消息的函数，进而响应式更新会话列表。会话和消息由store管理，组件从store中获取会话和消息的数据，进而响应式渲染UI。
```

## 详细说一下会话的增删改查、消息自动滚动到底部

```
会话增删改查
1. 首先会话列表是在store中管理的，store中将会话列表作为state，并将其存储在localStorage当中，然后将对话列表的增删改这些会引起会话状态变化的函数，都作为actions，一并return出去。组件从store中获取会话列表，并调用增删改函数，自然就可以实现会话的增删改查。
2. 查找的话，绑定搜索框的value值为keyword，使用数组的filter函数过滤关键字，展示过滤后的会话列表。

消息自动滚动到底部
1. 主要在于实时计算和更新滚动条的高度，滚动条的高度=整个消息容器的高度-容器可见区域高度，元素自身携带了这些高度的属性，比如scrollTop是滚动条高度，scrollHeight是整个容器的高度，clientHeight可见区域的高度。所以我们可以通过获取消息容器这个元素，获取到这些高度，进而实时更新滚动条的高度。vue中通过给元素绑定ref属性，获取该元素的DOM节点。
2. 还需要注意的一点是，滚动条的更新要放在nextTick这个API下面，需要等DOM节点都渲染完毕之后才可以计算。同时使用watch监听消息的变化，一旦变化就触发滚动条的计算，并把watch的immediate设为true，确保首次渲染时也自动滚动到底。
```

## 详细说一下md格式文档渲染与复制、代码块的高亮与复制

```
1. api返回的数据是markdown格式的字符串，我们需要把该字符串以markdown格式真正渲染到页面，而浏览器是不能直接解析md文档的，浏览器只能解析HTML，所以我们需要将md格式的文档转化为合适的HTML，再插入页面中。此处用到了markdown-it这个插件，完成md格式到HTML的转换。然后再使用v-html这个内置指令，将该HTML嵌入页面当中
2. 代码块的高亮使用highlight.js这个插件实现，在markdown-it插件的配置里，有代码高亮这个属性，把highlight.js的高亮函数传进去即可。
3. 普通文本块的复制，使用浏览器的提供的复制API navigaror.clipboard.writeText()将消息内容传进去复制即可
4. 代码块的复制，同样也是使用这个API，但关键点在于获取代码块的内容。使用markdown-it转换的md文档，包裹在一个pre标签里面，其中代码块又包裹在code标签里面，我们可以使用document.querySelector('code')获取code标签，然后使用textContent这个属性获取code标签下的内容，传给API，即可完成复制。还有一点是我们为所有的代码块都添加一个复制按钮，这时候同样是使用document.querySelectorAll获取所有pre元素，遍历pre元素，使用document.createElement创建button，使用appendChild将button按钮插入pre下。
```

## SSE  轮询  WebSocket

```

```

## get post请求的区别

```

```

## HTTP状态码

```

```

## onProgress

```

```

## 常见请求配置/请求头/响应头配置

```

```

## JWT认证/token

```

```

## nextTick

```

```

## Ref组件实例

```

```

